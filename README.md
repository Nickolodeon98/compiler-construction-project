# My first compiler construction using Java language
1.	Introduction
	The compiler has been finished up to syntactic analyser, or parser, and done partially for semantic analyser, with symbol table and code generation written in principle, but not fully working in practice. Although it is not complete, it seems that more than half of the requirements for being a compiler are fulfilled. Particularly, the whole lexical analyser and the syntactic analysing part of the parser are functioning perfectly. The semantic analyser has been implemented incompletely, there were some failures in implementing it. The whole function of catching semantic errors could not be realised. Nevertheless, the symbol table and the code generation of the compiler were attempted to be written and were actually positioned properly in the parser.
	The programming language used for the compiler is Java, and atom text editor was mainly employed in developing process. The reason why Java programming language was chosen as a development tool is because of its familiarity, but later it turned out that Jack language resembles Java which made the design process more straightforward. Also, as java is an object-oriented programming language, by creating different classes for each analysers of the compiler, the development stages could be followed more easily. However, even though there were clear milestones, they could not be kept well. Managing time efficiently was the most challenging aspect of this project, as the compiler construction itself was unfamiliar topic.
	The compiler has been tested using four sets of .jack files in Jack Programs folder provided in Minerva, on the DEC10 machines.


2.	The Lexical Analyser
	The lexical analyser has been designed following the one of suggestions provided in the lecture. This may be explained in three parts: reading the file, skipping the meaningless characters, extracting tokens.
	First of all, reading the file. The array was used as a container for storing the content of the file in order for the analyser to be able to access everything in the file. Therefore, at the beginning of the analyser, the file is opened and copied into ‘char’ type array. From this point, this array plays a role as a Jack program source code container on which lexical analysis is done without worrying about changing a file. Secondly, skipping the meaningless characters. Here, ‘meaningless characters’ means comments and whitespaces where nothing that could affect the behaviour of the program in running time, but are still useful and important when writing the code, exists. This is handled using if statements to distinguish the characters by their characteristics. Whitespaces are revealed obviously but comments should be deliberately considered. For comments, it is important to specify using if statements that they never end whatever next character analyser is reading, as long as ‘//’, ‘*’ or ‘/*’ exists on the same line before the current character. Thirdly, extracting tokens. The technique used here is not different to what is used in skipping the whitespaces and comments. Using the features of each types of tokens, the analyser finds out what sort of token it is processing at that moment. This basic structure of three parts constitutes two methods in the lexical analyser, GetNextToken() and PeekNextToken(). The only difference between two methods is that pointers are only moving in GetNextToken(), not in PeekNextToken().


3.	The Parser
	The parser was designed to be declaring several methods each of which representing the syntax of Jack language, according to Jack language grammar. This parser consists of methods having comprehensive names that describes the syntax it is dealing with. It prints out ‘OK’ for the correctly positioned tokens, and a line of error message if the token is placed at syntactically wrong place. How it is done is by referring to Jack language grammar and using GetNextToken() and PeekNextToken() methods from the lexical analyser. The syntax of each component of Jack program is known from the grammar. GetNextToken() is used when the token to be checked must be present for correct grammar, or in the other cases just to pass the current token and reach the next token. PeekNextToken() is used when the token to be checked could be there but not necessarily. The parser divides the whole jack source file into smaller partitions having own syntaxes and again splits them into tokens to inspect whether every small constituent is positioned correctly. In addition, this parser is recursive, in other words, it consists of recursive methods. The context is fairly important in syntactical analysis, therefore the calls to different methods and inspections of tokens are logically ordered, following Jack grammar. In order to compare the syntaxes currently being used in a given jack source code and correct syntaxes of standard jack program, String.equals() function of Java is used several times. For terminating the parser whenever the error is detected, System.exit(1) function is used.
	For testing the parser, sample Jack language source codes were employed. These identified where in the parser is defected, by showing error lines. When the parser had an issue, the error line was printed in a wrong place. The System.out.println() function was also useful in finding where in the code is not reached or is causing error.


4.	The Symbol Table
	The symbol table could have not been completed. However, the basic implementation is made possible, including defining some methods relevant to finding symbols, getting the type or offset of symbols and printing the symbols in symbol table. The symbol table is represented using List collection in Java. The symbols are indicated as class, having its kind, name or label, and offset as members. The tokens are added as symbols in Jack programs where the variables are declared, either as static, field, argument, or var variables. Variables of each kind are assigned offset uniquely as the memory segments are all distinguished. Thus, the offset is counted separately using different variable names, staticCount, fieldCount, argumentCount and varCount. As mentioned at the beginning of this paragraph, the methods are defined, which add, find and get information of the symbol using name, and sometimes symbol kind as well, given as parameter. They use iterator to look for a matching symbol in List of symbols, which represent the symbol table. Furthermore, as in Jack compiler there are more than one symbol table required for storing a variety of kinds of symbols, such as method-scope variables or class-scope variables, an array of more than one symbol tables is created in the compiler. However, it was not possible to store symbols in different types of tables, so only the first symbol table in an array is used. The symbol table is printed out in the text file called symbolTable.txt, after the syntactical analysis is done. Finally, there are still some spaces for improvements, only the argument kind symbols are added in symbol table.
This is what have been implemented as the symbol table so far.


5.	The Semantic Analyser
	The semantic analyser could not have been implemented due to time limit.


6.	Code Generation
	Accurate code generation is only possible when symbol table is fully implemented, therefore this part is not working correctly in practice. Nonetheless, this has been implemented in principle, as a result showing the proof of correctness in the code.
	In order to convert Jack language into Virtual Machine language, syntax of operand was analysed before everything else, because operand is used by every method of syntaxes, at last, as the parser is recursive.  There are many types of tokens that are regarded as operand, so the VM code varies. For integer-constant type variable, it was clear that ‘push constant’ command should be added. For identifier, it was important to get the kind of the variable, whether it is static, field, argument, or var. This was done by using the getSymbolType() method from SymbolTable class. Moreover, the offset of where in the memory is the variable stored could be obtained using getSymbolOffset() method. As it was determined that all generated codes are stored in an array and retrieved in runtime of compiler, VM code in string ‘"push " + kind + " " + offset’ was stored in array ‘vmCode’. This was done in a same manner for code generation in subroutineCall() method, where the function call is done, requiring the identifier type token as called function name. Besides, all the expressions and statements were added in each method appropriate VM code. For expressions, corresponding arithmetic and Boolean VM codes were introduced. Main components of expressions which are tokens of type symbols, were made being followed by VM commands, ‘add’ for “+”, ‘sub’ for “-”, ‘eq’ for “=”, etc. In statements methods, a variety of VM codes were added, from ‘"pop " + sKind + " " + offset’ under let statement to ‘"call do 1"’ in do statement. However, the issue encountered so far is that they are not stored in array as expected and do not print out correct code generation in text file output. This is still to be resolved.


7.	Compiler Usage Instructions
	To compile the compiler, first of all NickCompiler.java should be compiled. Then it could run as any of normal, general java programs. One thing that should be noted is that three files, NickLexer.java, NickCompiler.java and SymbolTable.java should be in one directory, together.
	In addition, when running the program after compiling NickCompiler.java, the file name should be specified. For instance, java NickCompiler String.jack may be the command for executing the program.
	Finally, the file path is now set as “Jack/Jack Programs/Set 4/”, and the image below shows this. This file path can always be changed. However, the program cannot read the file if the command is written with file path altogether.
For instance, java NickCompiler Jack/Jack Programs/Set 4/String.jack,  does not work.
Therefore, make sure either only the file name is specified or file path is modified in the code.
